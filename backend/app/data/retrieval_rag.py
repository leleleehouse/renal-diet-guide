from langchain_openai.chat_models import ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import json
from dotenv import load_dotenv


# Load environment variables from .env
load_dotenv()

# Load embeddings
embedding = HuggingFaceEmbeddings(
    model_name='jhgan/ko-sroberta-nli',
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True},
)

# Load FAISS vectorstore
vectorstore = FAISS.load_local(
    "/Users/idahyeon/renal-diet-guide/backend/app/data/rag_data",
    embeddings=embedding,
    allow_dangerous_deserialization=True
)

retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# Prompt must match RetrievalQA expected variables: context + question
prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="""
ë„ˆëŠ” ì‹ ì¥íˆ¬ì„ í™˜ìì˜ ì‹ì´ìš”ë²• ì „ë¬¸ê°€ì•¼.  
ì˜ë£Œì§„ê³¼ í™˜ìë“¤ì—ê²Œ ë„ì›€ì´ ë  ìˆ˜ ìˆë„ë¡, ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ì¥íˆ¬ì„ í™˜ìì˜ ì‹ì‚¬ ê´€ë¦¬ì— ëŒ€í•´ ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ì¤˜.  

â€» ë°˜ë“œì‹œ ì•„ë˜ ì‚¬í•­ì„ ë°˜ì˜í•´ ì‘ì„±í•  ê²ƒ:
- ë‹µë³€ì€ ì˜ë£Œì  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ë˜, ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ìœ¼ë¡œ ì„¤ëª…í•  ê²ƒ  
- íˆ¬ì„ í™˜ìì—ê²Œ ì¤‘ìš”í•œ ì˜ì–‘ì†Œ(ë‹¨ë°±ì§ˆ, ì¹¼ë¥¨, ì¸, ë‚˜íŠ¸ë¥¨, ìˆ˜ë¶„ ë“±)ì— ëŒ€í•œ ê³ ë ¤ì‚¬í•­ì„ ë°˜ì˜í•  ê²ƒ  
- ì‹¤ì œ ì‹ë‹¨ì´ë‚˜ ì‹ì¬ë£Œ ì˜ˆì‹œë¥¼ í¬í•¨í•´ êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ ì œê³µí•  ê²ƒ  
- í•„ìš” ì‹œ ì£¼ì˜ì‚¬í•­ì´ë‚˜ ê¸ˆê¸°ì‚¬í•­ë„ í•¨ê»˜ ì•ˆë‚´í•  ê²ƒ  


Context: {context}  
Question: {question}  

Answer in Korean:
"""
)

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.3, max_tokens=1025)


# Use custom prompt with RetrievalQA
qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs={"prompt": prompt}
)

# # Query must be passed as plain string to match expected 'question' input
# query = "ì‚¬ê³¼ ë¨¹ì–´ë„ ë¼?"
# result = qa.invoke({"query": query})

# # ğŸ’¬ ì¶œë ¥ (ê¸¸ì´ ì˜ë¦¼ ë°©ì§€)
# print("ğŸ’¬ Answer:")
# print(json.dumps(result, ensure_ascii=False, indent=2))
